{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('cakd3': conda)"
    },
    "interpreter": {
      "hash": "b54ea5334ac7e30e14c15345e162e7c7584df602af4968ddc075c99bdced931e"
    },
    "colab": {
      "name": "CH2_사이킷런.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkmina365/machine_learning_guide/blob/main/CH2_%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0Nqt5bxa_5j"
      },
      "source": [
        "# 1. sklearn\n",
        "- 모형 예측. 머신러닝의 가장 대표적인 라이브러리\n",
        "- 머신러닝 분석. 결과 관점에서 접근. 모형예측 평가에 특화\n",
        "- 6가지 기능\n",
        "   - 지도학습: 분류(Classification), 회귀(Regression)\n",
        "   - 비지도학습 : 범주화(Clustering), 차원축소/ 피처 추출(Feature extraction)\n",
        "   - 기타 : 모델선택 및 평가, 데이터 전처리 \n",
        "- 지도학습 : 명확한 정답(Label)이 주어진 데이터(Feature)를 학습 데이터 세트(Train)로 학습한 뒤 미지의 정답을 테스트 데이터 세트(Test)로 예측하는 방식\n",
        "- 예) LinearRegression, preprocessing, train_test_split, linear_model, metrics, Encoding\n",
        "\n",
        "\n",
        "\\- statsmodels 라이브러리와의 비교\n",
        "   - 통계 분석 및 추정. 모델 형성. 머신러닝도 가능하나 통계모델에 특화되어 있음\n",
        "   - 예) smf.ols, sm.qqplot, sm.stats.anova_lm, qq-plot, ANOVA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzwWDgqCa_5p"
      },
      "source": [
        "# 2. 예시: 붓꽃 품종 예측\n",
        "- 분류(Classification)기법 : 대표적 지도학습 방법\n",
        "- DecisionTreeClassifier 사용\n",
        "- load_iris : Feature(독립변수) 4가지를 기준으로 Label(종속변수) 3가지로 분류 하는 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMTgk7qWa_5r"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFZ5vuKma_5u",
        "outputId": "e41989c8-0a63-4f63-a43c-536e47a26a0f"
      },
      "source": [
        "# df 만들기\n",
        "iris = load_iris()\n",
        "print(iris.keys())\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS4S4Xy7a_5w"
      },
      "source": [
        "# train, test 분리하기\n",
        "X = iris_df.iloc[:,:-1]\n",
        "y = iris_df.iloc[:,-1]\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X,y,test_size=0.2,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVJIqgP9a_5w",
        "outputId": "a56cbcbf-d4f6-467e-d3fb-3d7e7f601189"
      },
      "source": [
        "# DecisionTreeClassifier 객체로 학습, 예측, 평가\n",
        "dt_clf = DecisionTreeClassifier()  # 객체 생성\n",
        "dt_clf.fit(X_train, y_train)       # 학습\n",
        "pred = dt_clf.predict(X_test)      # 예측\n",
        "accuracy_score(y_test, pred)       # 평가"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6PrKJMha_5x"
      },
      "source": [
        "# 3. sklearn 프레임워크\n",
        "- 지도학습 클래스(Estimator) : Classifier, Regressor 등 / fit(), predict()\n",
        "- 비지도학습 클래스 : fit(), transform(), fit_transform()\n",
        "- 평가 클래스 : cross_val_score\n",
        "- 하이퍼파라미터 튜닝 지원 클래스 : GridSearchCV\n",
        "- sklearn 주요 모듈\n",
        "   - sklearn.datasets\n",
        "   - sklearn.preprocessing: 전처리(인코딩, 정규화, 스케일링)\n",
        "   - sklearn.model_selection: 교차검증을 위한 학습/테스트 데이터 분리. GridSearch로 최적파라미터 추출 등\n",
        "   - sklearn.metrics: 성능 측정(분류, 회귀, 클러스터링 등). Accuracy, Precision, Recall, ROC-AUC, RMSE 등\n",
        "   - 알고리즘\n",
        "     - sklearn.ensenble: 앙상블 알고리즘. RandomForest, GBM 등\n",
        "     - sklearn.linear_model: linear, Logistic, Ridge, Lasso 등 회귀 알고리즘\n",
        "     - sklearn.neighbors: 최근접 이웃 알고리즘인 KNN 등\n",
        "     - sklearn.svm: Support Vector Machine\n",
        "     - sklearn.tree: 의사결정트리\n",
        "     - sklearn.cluster: 클러스터링 알고리즘. K-평균, 계층형 등\n",
        "     - sklearn.naive_bayes: 나이브 베이즈 알고리즘. 가우시안 NB 등"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0FrFrEOa_7C"
      },
      "source": [
        "# 4. sklearn.model_selection\n",
        "- 교차검증을 위한 학습/테스트 데이터 분리. 하이퍼파라미터 튜닝 등\n",
        "- 예) train_test_split, GridSearchCV "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk1fiS-Ca_7D"
      },
      "source": [
        "## 교차검증(CV:Cross Validation)\n",
        "- 학습용 데이터의 편중을 막기 위해 별도로 여러 세트로 구성된 학습용/테스트용 데이터 세트에서 학습과 평가를 여러번 수행. 각 세트에서 수행한 평가 결과에 따라 하이퍼 파라미터 튜닝 등의 모델 최적화가 가능\n",
        "- 학습용 데이터와 테스트용 데이터를 분리해서 모델링 및 평가를 수행하는 방식은 과적합에 취약한 약점이 있음. 고정된 테스트 데이터로만 평가를 하게되면 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 편향되게 모델을 유도하는 경향이 발생. 문제점을 개선하기 위하여 교차 검증(Cross Validation)을 이용해 다양한 학습과 평가를 수행\n",
        "  - 과적합: 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 때 예측 성능이 과도하게 떨어지는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwW-MlV5a_7F"
      },
      "source": [
        "### 1. KFold\n",
        "- K개의 데이터 폴드 세트를 만들어 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행. 전체 데이터를 K등분한 인덱스를 뽑아주는 개념\n",
        "- 데이터 세트를 K등분, 학습용 데이터와 테스트용 데이터를 K번 변경하면서 학습과 검증을 수행한 결과를 평균해서 평가 결과 산출\n",
        "- K번의 평가 점수의 평균으로 예측 성능을 평가함\n",
        "\n",
        "- https://m.blog.naver.com/ckdgus1433/221599517834"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FINXKQNa_7G",
        "outputId": "d7c6d9d7-3251-4037-ba03-ea37e638f300"
      },
      "source": [
        "# KFold로 교차검증\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "# K=5 개의 Fold로 분리하는 KFold 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "# Fold 세트별 평가(정확도)할 리스트 생성\n",
        "cv_accuracy =[]\n",
        "\n",
        "# KFold의 split(): Fold별 학습용, 테스트용 데이터의 index를 array로 반환\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(features):\n",
        "    # 학습용, 테스트용 데이터 분리\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    \n",
        "    # 학습, 예측\n",
        "    dt_clf.fit(X_train,y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    n_iter += 1\n",
        "\n",
        "    # 매 K마다 평가(정확도)\n",
        "    accuracy = accuracy_score(y_test,pred)\n",
        "    cv_accuracy.append(accuracy)\n",
        "    print(f'#{n_iter} CV 정확도 : {accuracy}\\nTest index : \\n{test_index}\\n')\n",
        "\n",
        "print(f'평균 CV 정확도 : {np.mean(cv_accuracy):.4f}')\n",
        "\n",
        "### Test index가 랜덤하지 않게 고르게 나뉘어져 있음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#1 CV 정확도 : 1.0\n",
            "Test index : \n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 CV 정확도 : 1.0\n",
            "Test index : \n",
            "[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 CV 정확도 : 0.8333333333333334\n",
            "Test index : \n",
            "[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 CV 정확도 : 0.9333333333333333\n",
            "Test index : \n",
            "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 CV 정확도 : 0.8333333333333334\n",
            "Test index : \n",
            "[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "평균 CV 정확도 : 0.9200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8qhpboMa_7H"
      },
      "source": [
        "### 2. Stratified KFold\n",
        "- 원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습용, 테스트용 데이터세트를 분배함\n",
        "- KFold가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 문제점을 개선함\n",
        "- 불균형한 분포도를 가진 레이블 데이터 집합을 위한 KFold 방식\n",
        "- Classfication의 CV는 Stratified KFold로 분할되어야 함\n",
        "- Regression의 label은 이산이 아닌 연속이기에 Stratified KFold 사용불가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLaWU2XZa_7I",
        "outputId": "59b77699-a765-4206-b7f1-ecca6c3196c2"
      },
      "source": [
        "# KFold의 문제점\n",
        "kfold = KFold(n_splits=3)\n",
        "n_iter=0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "    n_iter +=1\n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "    print(f'Fold:{n_iter}')\n",
        "    print(f'Train label value counts : \\n{label_train.value_counts()}')\n",
        "    print(f'Test label value counts : \\n{label_test.value_counts()}\\n')\n",
        "\n",
        "### Fold마다 Train과 Test의 label 분포가 다름"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold:1\n",
            "Train label value counts : \n",
            "1    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "Test label value counts : \n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Fold:2\n",
            "Train label value counts : \n",
            "0    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "Test label value counts : \n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Fold:3\n",
            "Train label value counts : \n",
            "0    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "Test label value counts : \n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cN6H3KIa_7J",
        "outputId": "e570faa4-6ee0-4b6c-e778-c6de10397c4f"
      },
      "source": [
        "# Stratified KFold 사용시 train, test label의 분포\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']): # label 추가\n",
        "    n_iter +=1\n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "    print(f'Fold:{n_iter}')\n",
        "    print(f'Train label value counts : \\n{label_train.value_counts()}')\n",
        "    print(f'Test label value counts : \\n{label_test.value_counts()}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold:1\n",
            "Train label value counts : \n",
            "2    34\n",
            "0    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "Test label value counts : \n",
            "0    17\n",
            "1    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Fold:2\n",
            "Train label value counts : \n",
            "1    34\n",
            "0    33\n",
            "2    33\n",
            "Name: label, dtype: int64\n",
            "Test label value counts : \n",
            "0    17\n",
            "2    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Fold:3\n",
            "Train label value counts : \n",
            "0    34\n",
            "1    33\n",
            "2    33\n",
            "Name: label, dtype: int64\n",
            "Test label value counts : \n",
            "1    17\n",
            "2    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxFlwusza_7L",
        "outputId": "93e4282b-5893-4efb-e6fa-ab55df839b66"
      },
      "source": [
        "# StratifiedKFold로 교차검증(CV)\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "cv_accuracy = []\n",
        "\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "    n_iter +=1\n",
        "    features_train = features[train_index]\n",
        "    features_test = features[test_index]\n",
        "    label_train = label[train_index]\n",
        "    label_test = label[test_index]\n",
        "\n",
        "    dt_clf.fit(features_train, label_train) # 학습\n",
        "    pred = dt_clf.predict(features_test)    # 예측\n",
        "    accuracy = accuracy_score(label_test, pred) # 평가\n",
        "    cv_accuracy.append(accuracy)\n",
        "    print(f'Fold:{n_iter}\\n정확도 : {accuracy_score(label_test, pred)}')\n",
        "    print(f'Test index : \\n{test_index}\\n')\n",
        "print(f'평균 정확도 : {np.mean(cv_accuracy):.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold:1\n",
            "정확도 : 0.98\n",
            "Test index : \n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "Fold:2\n",
            "정확도 : 0.94\n",
            "Test index : \n",
            "[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "Fold:3\n",
            "정확도 : 0.96\n",
            "Test index : \n",
            "[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "평균 정확도 : 0.9600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1pvMCr8a_7N"
      },
      "source": [
        "### 3. cross_val_score\n",
        "- Stratified KFold(회귀는 KFold)의 일련의 과정(학습,예측,평가)을 한꺼번에 수행 후 평가 지표를 출력\n",
        "- cross_val_score()는 하나의 평가 지표, cross_validate()는 여러개의 평가 지표\n",
        "- 주요 파라미터\n",
        "  - estimator: 모델 객체\n",
        "  - X, y\n",
        "  - scoring : 평가방식(accuracy 등)\n",
        "  - cv : fold 수\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzDnU8bZa_7N",
        "outputId": "1784fcca-19a5-4a64-9307-bdd0a4cc5c36"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "score = cross_val_score(dt_clf, features, label, scoring='accuracy', cv=3)\n",
        "print(f'CV별 정확도 : {score}\\n평균 정확도 : {np.mean(score)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV별 정확도 : [0.98 0.94 0.96]\n",
            "평균 정확도 : 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwYxCh2Fa_7O"
      },
      "source": [
        "### 4. GridSearchCV\n",
        "- CV 기반, 알고리즘에 사용되는 파라미터를 순차적으로 입력하며 예측 성능을 개선하는 최적의 파라미터(하이퍼 파라미터)을 도출함\n",
        "- Grid: 격자. 촘촘하게 여러 파라미터들을 엮어 테스트 함\n",
        "- CV(교차검증)와 하이퍼파라미터 튜닝을 한 번에 함\n",
        "- 주요 파라미터 : estimator, param_grid, scoring, cv, refit\n",
        "  - param_grid : estimator 튜닝을 위해 딕셔너리 형식으로 파라미터명과 사용될 파라미터들의 값을 지정\n",
        "  - refit : 디폴트 True. True로 생성 시 가장 최적의 하이퍼 파라미터를 찾은 뒤, 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습시킨다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54EIPqcaa_7O",
        "outputId": "fe94067d-48b0-4095-8bf1-f268eeca564f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd \n",
        "\n",
        "# train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, label,\\\n",
        "     test_size=0.2, random_state=0)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "# GridSearchCV 객체 만들기\n",
        "params = {'max_depth':[1,2,3],'min_samples_split':[2,3]}\n",
        "grid_dtree = GridSearchCV(estimator=dt_clf, param_grid=params, cv=3)\n",
        "\n",
        "# 학습\n",
        "grid_dtree.fit(X_train,y_train)\n",
        "\n",
        "# 결과 출력\n",
        "df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "display(df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']])\n",
        "print(grid_dtree.cv_results_.keys())\n",
        "print(f'\\n최적 하이퍼 파라미터 : {grid_dtree.best_params_}')\n",
        "print(f'최고 예측 정확도 : {grid_dtree.best_score_:.4f}')\n",
        "\n",
        "# 최적 파라미터 이용한 정확도 측정\n",
        "estimator = grid_dtree.best_estimator_\n",
        "pred = estimator.predict(X_test)\n",
        "print(f'테스트 데이터 세트 정확도 : {accuracy_score(y_test,pred):.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                     params  mean_test_score  rank_test_score  \\\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}         0.691667                5   \n",
              "1  {'max_depth': 1, 'min_samples_split': 3}         0.691667                5   \n",
              "2  {'max_depth': 2, 'min_samples_split': 2}         0.925000                3   \n",
              "3  {'max_depth': 2, 'min_samples_split': 3}         0.925000                3   \n",
              "4  {'max_depth': 3, 'min_samples_split': 2}         0.925000                1   \n",
              "5  {'max_depth': 3, 'min_samples_split': 3}         0.925000                1   \n",
              "\n",
              "   split0_test_score  split1_test_score  split2_test_score  \n",
              "0              0.700              0.700              0.675  \n",
              "1              0.700              0.700              0.675  \n",
              "2              0.850              0.975              0.950  \n",
              "3              0.850              0.975              0.950  \n",
              "4              0.925              0.900              0.950  \n",
              "5              0.925              0.900              0.950  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.850</td>\n",
              "      <td>0.975</td>\n",
              "      <td>0.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.850</td>\n",
              "      <td>0.975</td>\n",
              "      <td>0.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_max_depth', 'param_min_samples_split', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])\n",
            "\n",
            "최적 하이퍼 파라미터 : {'max_depth': 3, 'min_samples_split': 2}\n",
            "최고 예측 정확도 : 0.9250\n",
            "테스트 데이터 세트 정확도 : 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAyI1tlwa_7P"
      },
      "source": [
        "# 5. sklearn.preprocessing\n",
        "- feature 전처리 과정: Encoding, Scaling 등\n",
        "- 머신러닝 알고리즘은 문자열 값을 입력 값으로 허용하지 않음. 인코딩하여 숫자 값으로 변환해야\n",
        "  - 카테고리형 feature: 코드값으로 표현\n",
        "  - 텍스트형 feature: feature vectorization으로 벡터화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnZkztpSa_7P"
      },
      "source": [
        "## 1. LabelEncoder\n",
        "- 카테고리형 feature를 코드형 숫자값으로 변환\n",
        "- 숫자값은 단순 코드이지 숫자값에 따른 순서나 중요도로 인식되면 안됨. 선형회귀 등에는 적용하면 안됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB-wPhwDa_7P",
        "outputId": "9696b196-a518-4618-f322-fdc0d7c2e837"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoding\n",
        "items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(items)\n",
        "print(f'인코딩 변환값 : {labels}')\n",
        "print(f'인코딩 클래스 : {encoder.classes_}')\n",
        "\n",
        "# Decoding\n",
        "print(f'디코딩 원본값 : {encoder.inverse_transform(labels)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩 변환값 : [0 1 4 5 3 3 2 2]\n",
            "인코딩 클래스 : ['TV' '냉장고' '믹서' '선풍기' '전자렌지' '컴퓨터']\n",
            "디코딩 원본값 : ['TV' '냉장고' '전자렌지' '컴퓨터' '선풍기' '선풍기' '믹서' '믹서']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCNRrYMYa_7Q"
      },
      "source": [
        "## 2. OneHotEncoder\n",
        "- LabelEncoding의 단점 보완. feature값의 유형에 따라 새로운 feature를 추가해 고유값에 해당하는 칼럼에만 1표시하고 나머지엔 0표시\n",
        "- One-Hot: 여러개의 속성 중 단 한 개의 속성만 1로 표시\n",
        "- 문자형 데이터가 아닌 숫자형 데이터로 변환 후에 사용 가능하며, 2차원 데이터형태로 입력해야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7smGnClha_7Q",
        "outputId": "92ac6fcf-7322-4138-df50-380338ad54de"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# LabelEncoding 먼저 실시\n",
        "items = ['TV', '냉장고', '전자렌지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "encoder_l = LabelEncoder()\n",
        "labels = encoder_l.fit_transform(items).reshape(-1,1)\n",
        "\n",
        "# OneHotEncoding\n",
        "encoder = OneHotEncoder()\n",
        "labels1 = encoder.fit_transform(labels)\n",
        "labels1.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuyOkr7za_7R",
        "outputId": "f4e41975-4d5a-4b85-b905-00f0696995ee"
      },
      "source": [
        "# pd.get_dummies 이용\n",
        "import pandas as pd\n",
        "pd.get_dummies(items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   TV  냉장고  믹서  선풍기  전자렌지  컴퓨터\n",
              "0   1    0   0    0     0    0\n",
              "1   0    1   0    0     0    0\n",
              "2   0    0   0    0     1    0\n",
              "3   0    0   0    0     0    1\n",
              "4   0    0   0    1     0    0\n",
              "5   0    0   0    1     0    0\n",
              "6   0    0   1    0     0    0\n",
              "7   0    0   1    0     0    0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TV</th>\n",
              "      <th>냉장고</th>\n",
              "      <th>믹서</th>\n",
              "      <th>선풍기</th>\n",
              "      <th>전자렌지</th>\n",
              "      <th>컴퓨터</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbxhj5pQa_7R"
      },
      "source": [
        "## 3. StandardScaler\n",
        "- Feature Scaler 중 하나\n",
        "- 표준정규분포로 표준화(Standardization)\n",
        "- RBF 커널을 이용하는 SVM, LinearRegression, Logistic Regression은 데이터를 정규분포로 가정하고 구현되었기에 feature를 표준화하는게 좋음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avy3eS4Ya_7R",
        "outputId": "46e20a00-adff-4b8e-e330-184922d3d4ec"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "print(iris_df.mean())\n",
        "print()\n",
        "\n",
        "# StanardScaling\n",
        "scaler = StandardScaler()\n",
        "iris_scaled = scaler.fit_transform(iris_df)  # ndarray\n",
        "iris_scaled_df = pd.DataFrame(iris_scaled, columns=iris.feature_names)\n",
        "print(iris_scaled_df.mean().round(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "\n",
            "sepal length (cm)   -0.0\n",
            "sepal width (cm)    -0.0\n",
            "petal length (cm)   -0.0\n",
            "petal width (cm)    -0.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h9gpnfua_7S"
      },
      "source": [
        "## 4. MinMaxScaler\n",
        "- 0과 1사이의 값으로 정규화(Normalization)\n",
        "- 음수 값이 있을시, -1에서 1사이 값으로 변환\n",
        "- 데이터가 정규분포가 아닐시 시행\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB764GgXa_7S",
        "outputId": "aed04e8d-fc01-4eb0-b22c-0df21bbfb31b"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "iris_scaled = scaler.fit_transform(iris_df)\n",
        "iris_scaled_df = pd.DataFrame(iris_scaled, columns=iris.feature_names)\n",
        "display(iris_scaled_df.mean(), iris_scaled_df.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sepal length (cm)    0.428704\n",
              "sepal width (cm)     0.440556\n",
              "petal length (cm)    0.467458\n",
              "petal width (cm)     0.458056\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
              "count         150.000000        150.000000         150.000000   \n",
              "mean            0.428704          0.440556           0.467458   \n",
              "std             0.230018          0.181611           0.299203   \n",
              "min             0.000000          0.000000           0.000000   \n",
              "25%             0.222222          0.333333           0.101695   \n",
              "50%             0.416667          0.416667           0.567797   \n",
              "75%             0.583333          0.541667           0.694915   \n",
              "max             1.000000          1.000000           1.000000   \n",
              "\n",
              "       petal width (cm)  \n",
              "count        150.000000  \n",
              "mean           0.458056  \n",
              "std            0.317599  \n",
              "min            0.000000  \n",
              "25%            0.083333  \n",
              "50%            0.500000  \n",
              "75%            0.708333  \n",
              "max            1.000000  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.428704</td>\n",
              "      <td>0.440556</td>\n",
              "      <td>0.467458</td>\n",
              "      <td>0.458056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.230018</td>\n",
              "      <td>0.181611</td>\n",
              "      <td>0.299203</td>\n",
              "      <td>0.317599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.101695</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.567797</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.694915</td>\n",
              "      <td>0.708333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}